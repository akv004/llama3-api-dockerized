apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama3-api-deployment
  namespace: synapse  # <-- ADD THIS
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llama3-api
  template:
    metadata:
      labels:
        app: llama3-api
    spec:
      containers:
      - name: llama3-api
        image: your-username/llama3-api:latest
        ports:
        - containerPort: 8002
        env:
        # --- ADDED: Hugging Face Cache Environment Variables ---
        - name: HF_HOME
          value: "/home/appuser/.cache/huggingface"
        - name: HUGGINGFACE_HUB_CACHE
          value: "/home/appuser/.cache/huggingface/hub"
        # --- Other Environment Variables ---
        - name: REDIS_URL
          value: "redis://redis-service:6379/0" 
        - name: FAISS_DIR
          value: "/data/my_rag_data"
        - name: HUGGINGFACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-secret
              key: token
        volumeMounts:
        # --- ADDED: Mount for the Hugging Face Cache ---
        - name: hf-cache-volume
          mountPath: /home/appuser/.cache/huggingface
        # --- Other Volume Mounts ---
        - name: rag-data-volume
          mountPath: /data/my_rag_data
        - name: log-volume
          mountPath: /home/appuser/app/logs
        resources:
          limits:
            nvidia.com/gpu: 1
      volumes:
      # --- ADDED: Volume Definition for the Host Cache ---
      - name: hf-cache-volume
        hostPath:
          path: /home/amit/projects/.cache/huggingface # <-- This is your local path
          type: DirectoryOrCreate
      # --- Other Volume Definitions ---
      - name: rag-data-volume
        hostPath:
          path: /home/amit/projects/my_rag_data # <-- Example path, adjust as needed
      - name: log-volume
        hostPath:
          path: /home/amit/projects/logs